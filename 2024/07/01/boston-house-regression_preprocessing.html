<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Hands-On with Linear Regression: Boston Housing Edition | Bioinformatics for Beginners</title>
<meta name="generator" content="Jekyll v4.4.1" />
<meta property="og:title" content="Hands-On with Linear Regression: Boston Housing Edition" />
<meta name="author" content="Tushar Singh" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Note: This project was part of my learning journey, not a tutorial." />
<meta property="og:description" content="Note: This project was part of my learning journey, not a tutorial." />
<meta property="og:site_name" content="Bioinformatics for Beginners" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-07-01T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Hands-On with Linear Regression: Boston Housing Edition" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Tushar Singh"},"dateModified":"2024-07-01T00:00:00+00:00","datePublished":"2024-07-01T00:00:00+00:00","description":"Note: This project was part of my learning journey, not a tutorial.","headline":"Hands-On with Linear Regression: Boston Housing Edition","mainEntityOfPage":{"@type":"WebPage","@id":"/2024/07/01/boston-house-regression_preprocessing.html"},"url":"/2024/07/01/boston-house-regression_preprocessing.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="/feed.xml" title="Bioinformatics for Beginners" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Bioinformatics for Beginners</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/">Bioinformatics for Beginners</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Hands-On with Linear Regression: Boston Housing Edition</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2024-07-01T00:00:00+00:00" itemprop="datePublished">Jul 1, 2024
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <blockquote>
  <p><strong>Note:</strong> This project was part of my learning journey, not a tutorial.</p>
</blockquote>

<p>The Boston Housing dataset is one of the classic beginner projects in machine learning. I worked on this as part of my learning journey and wanted to share a few key steps that I personally found interesting or worth paying attention to.</p>

<p>This isn’t meant to be a full tutorial — instead, I’ll walk through the main parts of the process that stood out to me: how we test relationships between features, apply log transformations, evaluate model fit using BIC, and use RMSE to build a prediction range.</p>

<p>Along the way, I’ll also be trying out a few different ways to visualize the results — mostly just to explore more plotting options and get better at using them. These variations aren’t necessary to follow, but they all use the same core functions and are good for practice.</p>

<p>The idea is to keep things simple and practical. If you’re also exploring ML and want to build intuition for how regression works in real datasets, I hope this post helps you spot the “why” behind some of the steps — not just the code itself.</p>

<h2 id="import-libraries">Import Libraries</h2>

<blockquote>
  <p>We begin by importing essential libraries for:</p>
  <ul>
    <li>data handling (<code class="language-plaintext highlighter-rouge">pandas</code>, <code class="language-plaintext highlighter-rouge">numpy</code>)</li>
    <li>plotting (<code class="language-plaintext highlighter-rouge">seaborn</code>, <code class="language-plaintext highlighter-rouge">matplotlib</code>)</li>
    <li>statistical modeling and diagnostics (<code class="language-plaintext highlighter-rouge">statsmodels</code>, <code class="language-plaintext highlighter-rouge">math</code>, <code class="language-plaintext highlighter-rouge">sklearn</code>)</li>
    <li>and suppressing warnings to keep the notebook output clean.</li>
  </ul>
</blockquote>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># from sklearn.datasets import load_boston
</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">seaborn</span> <span class="k">as</span> <span class="n">sb</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span> <span class="k">as</span> <span class="n">tts</span>
<span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span> <span class="k">as</span> <span class="n">LR</span>
<span class="kn">from</span> <span class="n">math</span> <span class="kn">import</span> <span class="n">log</span>
<span class="kn">import</span> <span class="n">statsmodels.api</span> <span class="k">as</span> <span class="n">sm</span>
<span class="kn">from</span> <span class="n">statsmodels.stats.outliers_influence</span> <span class="kn">import</span> <span class="n">variance_inflation_factor</span> <span class="k">as</span> <span class="n">vif</span>
</code></pre></div></div>
<h2 id="load-the-boston-housing-dataset-from-url">Load the Boston Housing Dataset from URL</h2>

<blockquote>
  <p>The dataset is fetched directly from Carnegie Mellon University’s open data repository.<br />
The file format is unusual — every data sample spans <strong>two rows</strong>:</p>
  <ul>
    <li>The first row has 12 features</li>
    <li>The second row has the remaining 2 features + the target value (housing price)</li>
  </ul>
</blockquote>

<p>We use:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">read_csv()</code> with a custom separator (<code class="language-plaintext highlighter-rouge">\\s+</code>) to handle whitespace</li>
  <li><code class="language-plaintext highlighter-rouge">skiprows=22</code> to skip the descriptive header</li>
  <li><code class="language-plaintext highlighter-rouge">np.hstack()</code> to horizontally stack every pair of rows:
    <ul>
      <li>the 1st, 3rd, 5th rows for features</li>
      <li>the 2nd, 4th, 6th rows for extra features and target</li>
    </ul>
  </li>
  <li>We extract the third column from every second row as the target variable (<code class="language-plaintext highlighter-rouge">target</code>)</li>
</ul>

<p>This preprocessing reconstructs the dataset into a proper format where each row represents one complete data point.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_url</span> <span class="o">=</span> <span class="sh">"</span><span class="s">http://lib.stat.cmu.edu/datasets/boston</span><span class="sh">"</span>
<span class="n">raw_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="n">data_url</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="sh">"</span><span class="se">\\</span><span class="s">s+</span><span class="sh">"</span><span class="p">,</span> <span class="n">skiprows</span><span class="o">=</span><span class="mi">22</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">hstack</span><span class="p">([</span><span class="n">raw_df</span><span class="p">.</span><span class="n">values</span><span class="p">[::</span><span class="mi">2</span><span class="p">,</span> <span class="p">:],</span> <span class="n">raw_df</span><span class="p">.</span><span class="n">values</span><span class="p">[</span><span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]])</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">raw_df</span><span class="p">.</span><span class="n">values</span><span class="p">[</span><span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>

</code></pre></div></div>

<h2 id="verify-data-structure-after-reconstruction">Verify Data Structure After Reconstruction</h2>

<blockquote>
  <p>After combining rows using <code class="language-plaintext highlighter-rouge">np.hstack</code>, we check the shape and content of our dataset:</p>

  <ul>
    <li><code class="language-plaintext highlighter-rouge">data.shape</code> confirms that we now have <strong>506 rows and 13 columns</strong>, meaning 506 complete data points (each with 13 features).</li>
    <li><code class="language-plaintext highlighter-rouge">data[0]</code> prints the <strong>first data sample</strong>, helping us visually inspect that the reconstruction worked correctly and values are aligned.</li>
  </ul>
</blockquote>

<p>This step is crucial for validating that our reshaping logic hasn’t misaligned any features or rows — a silent bug here could break all downstream analysis.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(506, 13)
[6.320e-03 1.800e+01 2.310e+00 0.000e+00 5.380e-01 6.575e+00 6.520e+01
 4.090e+00 1.000e+00 2.960e+02 1.530e+01 3.969e+02 4.980e+00]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">features</span> <span class="o">=</span> <span class="p">[</span>
    <span class="sh">"</span><span class="s">CRIM</span><span class="sh">"</span><span class="p">,</span>     <span class="c1"># per capita crime rate by town
</span>    <span class="sh">"</span><span class="s">ZN</span><span class="sh">"</span><span class="p">,</span>       <span class="c1"># proportion of residential land zoned for lots over 25,000 sq.ft.
</span>    <span class="sh">"</span><span class="s">INDUS</span><span class="sh">"</span><span class="p">,</span>    <span class="c1"># proportion of non-retail business acres per town
</span>    <span class="sh">"</span><span class="s">CHAS</span><span class="sh">"</span><span class="p">,</span>     <span class="c1"># Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)
</span>    <span class="sh">"</span><span class="s">NOX</span><span class="sh">"</span><span class="p">,</span>      <span class="c1"># nitric oxides concentration (parts per 10 million)
</span>    <span class="sh">"</span><span class="s">RM</span><span class="sh">"</span><span class="p">,</span>       <span class="c1"># average number of rooms per dwelling
</span>    <span class="sh">"</span><span class="s">AGE</span><span class="sh">"</span><span class="p">,</span>      <span class="c1"># proportion of owner-occupied units built prior to 1940
</span>    <span class="sh">"</span><span class="s">DIS</span><span class="sh">"</span><span class="p">,</span>      <span class="c1"># weighted distances to five Boston employment centres
</span>    <span class="sh">"</span><span class="s">RAD</span><span class="sh">"</span><span class="p">,</span>      <span class="c1"># index of accessibility to radial highways
</span>    <span class="sh">"</span><span class="s">TAX</span><span class="sh">"</span><span class="p">,</span>      <span class="c1"># full-value property-tax rate per $10,000
</span>    <span class="sh">"</span><span class="s">PTRATIO</span><span class="sh">"</span><span class="p">,</span>  <span class="c1"># pupil-teacher ratio by town
</span>    <span class="sh">"</span><span class="s">B</span><span class="sh">"</span><span class="p">,</span>        <span class="c1"># 1000(Bk - 0.63)^2 where Bk is the proportion of Black residents by town
</span>    <span class="sh">"</span><span class="s">LSTAT</span><span class="sh">"</span>     <span class="c1"># % lower status of the population
</span><span class="p">]</span>

</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span><span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span> <span class="n">data</span> <span class="p">,</span> <span class="n">columns</span><span class="o">=</span> <span class="n">features</span><span class="p">)</span>

<span class="n">data</span><span class="p">[</span><span class="sh">"</span><span class="s">PRICE</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">target</span>

<span class="nf">print</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        CRIM    ZN  INDUS  CHAS    NOX  ...    TAX  PTRATIO       B  LSTAT  PRICE
0    0.00632  18.0   2.31   0.0  0.538  ...  296.0     15.3  396.90   4.98   24.0
1    0.02731   0.0   7.07   0.0  0.469  ...  242.0     17.8  396.90   9.14   21.6
2    0.02729   0.0   7.07   0.0  0.469  ...  242.0     17.8  392.83   4.03   34.7
3    0.03237   0.0   2.18   0.0  0.458  ...  222.0     18.7  394.63   2.94   33.4
4    0.06905   0.0   2.18   0.0  0.458  ...  222.0     18.7  396.90   5.33   36.2
..       ...   ...    ...   ...    ...  ...    ...      ...     ...    ...    ...
501  0.06263   0.0  11.93   0.0  0.573  ...  273.0     21.0  391.99   9.67   22.4
502  0.04527   0.0  11.93   0.0  0.573  ...  273.0     21.0  396.90   9.08   20.6
503  0.06076   0.0  11.93   0.0  0.573  ...  273.0     21.0  396.90   5.64   23.9
504  0.10959   0.0  11.93   0.0  0.573  ...  273.0     21.0  393.45   6.48   22.0
505  0.04741   0.0  11.93   0.0  0.573  ...  273.0     21.0  396.90   7.88   11.9

[506 rows x 14 columns]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span><span class="p">.</span><span class="nf">tail</span><span class="p">()</span>
</code></pre></div></div>
<p>&lt;/div&gt;</p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CRIM</th>
      <th>ZN</th>
      <th>INDUS</th>
      <th>CHAS</th>
      <th>NOX</th>
      <th>RM</th>
      <th>AGE</th>
      <th>DIS</th>
      <th>RAD</th>
      <th>TAX</th>
      <th>PTRATIO</th>
      <th>B</th>
      <th>LSTAT</th>
      <th>PRICE</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>501</th>
      <td>0.06263</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.593</td>
      <td>69.1</td>
      <td>2.4786</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>391.99</td>
      <td>9.67</td>
      <td>22.4</td>
    </tr>
    <tr>
      <th>502</th>
      <td>0.04527</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.120</td>
      <td>76.7</td>
      <td>2.2875</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>9.08</td>
      <td>20.6</td>
    </tr>
    <tr>
      <th>503</th>
      <td>0.06076</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.976</td>
      <td>91.0</td>
      <td>2.1675</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>5.64</td>
      <td>23.9</td>
    </tr>
    <tr>
      <th>504</th>
      <td>0.10959</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.794</td>
      <td>89.3</td>
      <td>2.3889</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>393.45</td>
      <td>6.48</td>
      <td>22.0</td>
    </tr>
    <tr>
      <th>505</th>
      <td>0.04741</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.030</td>
      <td>80.8</td>
      <td>2.5050</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>7.88</td>
      <td>11.9</td>
    </tr>
  </tbody>
</table>
<p>&lt;/div&gt;</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span><span class="p">.</span><span class="nf">count</span><span class="p">()</span>    <span class="c1">### num of rows for each col 
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>CRIM       506
ZN         506
INDUS      506
CHAS       506
NOX        506
RM         506
AGE        506
DIS        506
RAD        506
TAX        506
PTRATIO    506
B          506
LSTAT      506
PRICE      506
dtype: int64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># any(pd.isnull(data))
</span><span class="n">pd</span><span class="p">.</span><span class="nf">isnull</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="nf">any</span><span class="p">()</span>

</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>CRIM       False
ZN         False
INDUS      False
CHAS       False
NOX        False
RM         False
AGE        False
DIS        False
RAD        False
TAX        False
PTRATIO    False
B          False
LSTAT      False
PRICE      False
dtype: bool
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span><span class="p">.</span><span class="nf">info</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 506 entries, 0 to 505
Data columns (total 14 columns):
 #   Column   Non-Null Count  Dtype  
---  ------   --------------  -----  
 0   CRIM     506 non-null    float64
 1   ZN       506 non-null    float64
 2   INDUS    506 non-null    float64
 3   CHAS     506 non-null    float64
 4   NOX      506 non-null    float64
 5   RM       506 non-null    float64
 6   AGE      506 non-null    float64
 7   DIS      506 non-null    float64
 8   RAD      506 non-null    float64
 9   TAX      506 non-null    float64
 10  PTRATIO  506 non-null    float64
 11  B        506 non-null    float64
 12  LSTAT    506 non-null    float64
 13  PRICE    506 non-null    float64
dtypes: float64(14)
memory usage: 55.5 KB
</code></pre></div></div>

<h2 id="visualize-the-distribution-of-housing-prices">Visualize the Distribution of Housing Prices</h2>

<blockquote>
  <p>Before modeling, it’s helpful to understand the <strong>distribution of the target variable</strong> — in this case, <code class="language-plaintext highlighter-rouge">PRICE</code> (in $1000s).</p>
</blockquote>

<p>We plot a histogram with:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">bins=30</code> for smoother granularity</li>
  <li>a clean visual style (<code class="language-plaintext highlighter-rouge">teal</code> color, black edges, slight transparency)</li>
  <li>labeled axes for readability</li>
</ul>

<p>This plot helps us see:</p>
<ul>
  <li>Whether the target is normally distributed</li>
  <li>If there are <strong>outliers</strong> or <strong>skew</strong> (e.g., a long tail to the right)</li>
  <li>Whether we might need to apply a transformation (like log) later</li>
</ul>

<blockquote>
  <p>Note: If you’re getting an error like <code class="language-plaintext highlighter-rouge">TypeError: 'numpy.ndarray' object is not subscriptable</code>, make sure <code class="language-plaintext highlighter-rouge">data</code> is a DataFrame, not a NumPy array, before plotting.</p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="nc">Figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">hist</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="sh">"</span><span class="s">PRICE</span><span class="sh">"</span><span class="p">],</span><span class="n">bins</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="sh">"</span><span class="s">teal</span><span class="sh">"</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="sh">"</span><span class="s">black</span><span class="sh">"</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span> <span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Prices in 1000s</span><span class="sh">"</span><span class="p">,</span> <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Num of houses</span><span class="sh">"</span><span class="p">,</span><span class="n">fontsize</span> <span class="o">=</span> <span class="mi">12</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Text(0, 0.5, 'Num of houses')
</code></pre></div></div>

<p><img src="/main_files/main_13_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sb</span><span class="p">.</span><span class="nf">displot</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">PRICE</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span><span class="n">kde</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1"># sb.displot(data.PRICE)
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;seaborn.axisgrid.FacetGrid at 0x17dbd38d0&gt;
</code></pre></div></div>

<p><img src="/main_files/main_14_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span><span class="p">.</span><span class="nf">describe</span><span class="p">()</span>
</code></pre></div></div>
<p>&lt;/div&gt;</p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CRIM</th>
      <th>ZN</th>
      <th>INDUS</th>
      <th>CHAS</th>
      <th>NOX</th>
      <th>RM</th>
      <th>AGE</th>
      <th>DIS</th>
      <th>RAD</th>
      <th>TAX</th>
      <th>PTRATIO</th>
      <th>B</th>
      <th>LSTAT</th>
      <th>PRICE</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>506.000000</td>
      <td>506.000000</td>
      <td>506.000000</td>
      <td>506.000000</td>
      <td>506.000000</td>
      <td>506.000000</td>
      <td>506.000000</td>
      <td>506.000000</td>
      <td>506.000000</td>
      <td>506.000000</td>
      <td>506.000000</td>
      <td>506.000000</td>
      <td>506.000000</td>
      <td>506.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>3.613524</td>
      <td>11.363636</td>
      <td>11.136779</td>
      <td>0.069170</td>
      <td>0.554695</td>
      <td>6.284634</td>
      <td>68.574901</td>
      <td>3.795043</td>
      <td>9.549407</td>
      <td>408.237154</td>
      <td>18.455534</td>
      <td>356.674032</td>
      <td>12.653063</td>
      <td>22.532806</td>
    </tr>
    <tr>
      <th>std</th>
      <td>8.601545</td>
      <td>23.322453</td>
      <td>6.860353</td>
      <td>0.253994</td>
      <td>0.115878</td>
      <td>0.702617</td>
      <td>28.148861</td>
      <td>2.105710</td>
      <td>8.707259</td>
      <td>168.537116</td>
      <td>2.164946</td>
      <td>91.294864</td>
      <td>7.141062</td>
      <td>9.197104</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.006320</td>
      <td>0.000000</td>
      <td>0.460000</td>
      <td>0.000000</td>
      <td>0.385000</td>
      <td>3.561000</td>
      <td>2.900000</td>
      <td>1.129600</td>
      <td>1.000000</td>
      <td>187.000000</td>
      <td>12.600000</td>
      <td>0.320000</td>
      <td>1.730000</td>
      <td>5.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>0.082045</td>
      <td>0.000000</td>
      <td>5.190000</td>
      <td>0.000000</td>
      <td>0.449000</td>
      <td>5.885500</td>
      <td>45.025000</td>
      <td>2.100175</td>
      <td>4.000000</td>
      <td>279.000000</td>
      <td>17.400000</td>
      <td>375.377500</td>
      <td>6.950000</td>
      <td>17.025000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>0.256510</td>
      <td>0.000000</td>
      <td>9.690000</td>
      <td>0.000000</td>
      <td>0.538000</td>
      <td>6.208500</td>
      <td>77.500000</td>
      <td>3.207450</td>
      <td>5.000000</td>
      <td>330.000000</td>
      <td>19.050000</td>
      <td>391.440000</td>
      <td>11.360000</td>
      <td>21.200000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>3.677083</td>
      <td>12.500000</td>
      <td>18.100000</td>
      <td>0.000000</td>
      <td>0.624000</td>
      <td>6.623500</td>
      <td>94.075000</td>
      <td>5.188425</td>
      <td>24.000000</td>
      <td>666.000000</td>
      <td>20.200000</td>
      <td>396.225000</td>
      <td>16.955000</td>
      <td>25.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>88.976200</td>
      <td>100.000000</td>
      <td>27.740000</td>
      <td>1.000000</td>
      <td>0.871000</td>
      <td>8.780000</td>
      <td>100.000000</td>
      <td>12.126500</td>
      <td>24.000000</td>
      <td>711.000000</td>
      <td>22.000000</td>
      <td>396.900000</td>
      <td>37.970000</td>
      <td>50.000000</td>
    </tr>
  </tbody>
</table>
<p>&lt;/div&gt;</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="nc">Figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">hist</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="sh">"</span><span class="s">RM</span><span class="sh">"</span><span class="p">],</span><span class="n">bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="sh">"</span><span class="s">orange</span><span class="sh">"</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="sh">"</span><span class="s">black</span><span class="sh">"</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span> <span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Rooms</span><span class="sh">"</span><span class="p">,</span> <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Num of houses</span><span class="sh">"</span><span class="p">,</span><span class="n">fontsize</span> <span class="o">=</span> <span class="mi">12</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Text(0, 0.5, 'Num of houses')
</code></pre></div></div>

<p><img src="/main_files/main_16_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="nc">Figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">hist</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="sh">"</span><span class="s">LSTAT</span><span class="sh">"</span><span class="p">],</span><span class="n">bins</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="sh">"</span><span class="s">red</span><span class="sh">"</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="sh">"</span><span class="s">black</span><span class="sh">"</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span> <span class="p">,</span> <span class="n">rwidth</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Polution</span><span class="sh">"</span><span class="p">,</span> <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Num of houses</span><span class="sh">"</span><span class="p">,</span><span class="n">fontsize</span> <span class="o">=</span> <span class="mi">12</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Text(0, 0.5, 'Num of houses')
</code></pre></div></div>

<p><img src="/main_files/main_17_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span><span class="p">.</span><span class="n">RAD</span><span class="p">.</span><span class="nf">value_counts</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>RAD
24.0    132
5.0     115
4.0     110
3.0      38
6.0      26
2.0      24
8.0      24
1.0      20
7.0      17
Name: count, dtype: int64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="nc">Figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="c1"># plt.hist(data["RAD"],bins=25, color = "grey", edgecolor="black", alpha=0.8 )
</span><span class="n">plt</span><span class="p">.</span><span class="nf">hist</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="sh">"</span><span class="s">RAD</span><span class="sh">"</span><span class="p">],</span><span class="n">bins</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="sh">"</span><span class="s">grey</span><span class="sh">"</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="sh">"</span><span class="s">black</span><span class="sh">"</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">rwidth</span><span class="o">=</span><span class="mf">0.7</span> <span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Access to Highways</span><span class="sh">"</span><span class="p">,</span> <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Num of houses</span><span class="sh">"</span><span class="p">,</span><span class="n">fontsize</span> <span class="o">=</span> <span class="mi">12</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Text(0, 0.5, 'Num of houses')
</code></pre></div></div>

<p><img src="/main_files/main_19_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">###flexible way of making these without hardcoding 
</span>
<span class="n">freq</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">RAD</span><span class="p">.</span><span class="nf">value_counts</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="n">freq</span><span class="p">.</span><span class="n">index</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">bar</span><span class="p">(</span><span class="n">freq</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="n">freq</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="sh">"</span><span class="s">grey</span><span class="sh">"</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="sh">"</span><span class="s">black</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Access to Highways</span><span class="sh">"</span><span class="p">,</span> <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Num of houses</span><span class="sh">"</span><span class="p">,</span><span class="n">fontsize</span> <span class="o">=</span> <span class="mi">12</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Index([24.0, 5.0, 4.0, 3.0, 6.0, 2.0, 8.0, 1.0, 7.0], dtype='float64', name='RAD')





Text(0, 0.5, 'Num of houses')
</code></pre></div></div>

<p><img src="/main_files/main_20_2.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span><span class="p">.</span><span class="n">CHAS</span><span class="p">.</span><span class="nf">value_counts</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>CHAS
0.0    471
1.0     35
Name: count, dtype: int64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span><span class="p">.</span><span class="nf">min</span><span class="p">()</span>    <span class="c1">## min value in every col 
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>CRIM         0.00632
ZN           0.00000
INDUS        0.46000
CHAS         0.00000
NOX          0.38500
RM           3.56100
AGE          2.90000
DIS          1.12960
RAD          1.00000
TAX        187.00000
PTRATIO     12.60000
B            0.32000
LSTAT        1.73000
PRICE        5.00000
dtype: float64
</code></pre></div></div>

<h2 id="check-linear-correlation-between-features-and-target">Check Linear Correlation Between Features and Target</h2>

<blockquote>
  <p>We loop through each feature and calculate its <strong>Pearson correlation</strong> with <code class="language-plaintext highlighter-rouge">PRICE</code>.</p>
</blockquote>

<ul>
  <li>Pearson correlation ranges from <strong>-1 to 1</strong>:
    <ul>
      <li><code class="language-plaintext highlighter-rouge">+1</code>: perfect positive linear relationship</li>
      <li><code class="language-plaintext highlighter-rouge">-1</code>: perfect negative linear relationship</li>
      <li><code class="language-plaintext highlighter-rouge">0</code>: no linear relationship</li>
    </ul>
  </li>
  <li>This helps us <strong>identify features that are strongly correlated</strong> with the target — useful for linear regression.</li>
</ul>

<blockquote>
  <p>Features with high positive or negative correlation to <code class="language-plaintext highlighter-rouge">PRICE</code> may be strong predictors.</p>
</blockquote>

<p>This step also gives us a quick numeric intuition of which features are likely to be useful in the model and which may not contribute much.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">cols</span> <span class="ow">in</span> <span class="n">data</span><span class="p">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">cols</span> <span class="o">!=</span> <span class="sh">"</span><span class="s">PRICE</span><span class="sh">"</span><span class="p">:</span>
        <span class="n">corr</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="sh">"</span><span class="s">PRICE</span><span class="sh">"</span><span class="p">].</span><span class="nf">corr</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">cols</span><span class="p">])</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Corr with </span><span class="si">{</span><span class="n">cols</span><span class="si">}</span><span class="s">:   </span><span class="si">{</span><span class="n">corr</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Corr with CRIM:   -0.38830460858681143
Corr with ZN:   0.3604453424505435
Corr with INDUS:   -0.48372516002837357
Corr with CHAS:   0.1752601771902987
Corr with NOX:   -0.4273207723732826
Corr with RM:   0.6953599470715393
Corr with AGE:   -0.37695456500459623
Corr with DIS:   0.24992873408590394
Corr with RAD:   -0.3816262306397775
Corr with TAX:   -0.46853593356776685
Corr with PTRATIO:   -0.5077866855375616
Corr with B:   0.3334608196570666
Corr with LSTAT:   -0.7376627261740151
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span><span class="p">.</span><span class="nf">corr</span><span class="p">()</span>
</code></pre></div></div>
<p>&lt;/div&gt;
&lt;/style&gt;</p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CRIM</th>
      <th>ZN</th>
      <th>INDUS</th>
      <th>CHAS</th>
      <th>NOX</th>
      <th>RM</th>
      <th>AGE</th>
      <th>DIS</th>
      <th>RAD</th>
      <th>TAX</th>
      <th>PTRATIO</th>
      <th>B</th>
      <th>LSTAT</th>
      <th>PRICE</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>CRIM</th>
      <td>1.000000</td>
      <td>-0.200469</td>
      <td>0.406583</td>
      <td>-0.055892</td>
      <td>0.420972</td>
      <td>-0.219247</td>
      <td>0.352734</td>
      <td>-0.379670</td>
      <td>0.625505</td>
      <td>0.582764</td>
      <td>0.289946</td>
      <td>-0.385064</td>
      <td>0.455621</td>
      <td>-0.388305</td>
    </tr>
    <tr>
      <th>ZN</th>
      <td>-0.200469</td>
      <td>1.000000</td>
      <td>-0.533828</td>
      <td>-0.042697</td>
      <td>-0.516604</td>
      <td>0.311991</td>
      <td>-0.569537</td>
      <td>0.664408</td>
      <td>-0.311948</td>
      <td>-0.314563</td>
      <td>-0.391679</td>
      <td>0.175520</td>
      <td>-0.412995</td>
      <td>0.360445</td>
    </tr>
    <tr>
      <th>INDUS</th>
      <td>0.406583</td>
      <td>-0.533828</td>
      <td>1.000000</td>
      <td>0.062938</td>
      <td>0.763651</td>
      <td>-0.391676</td>
      <td>0.644779</td>
      <td>-0.708027</td>
      <td>0.595129</td>
      <td>0.720760</td>
      <td>0.383248</td>
      <td>-0.356977</td>
      <td>0.603800</td>
      <td>-0.483725</td>
    </tr>
    <tr>
      <th>CHAS</th>
      <td>-0.055892</td>
      <td>-0.042697</td>
      <td>0.062938</td>
      <td>1.000000</td>
      <td>0.091203</td>
      <td>0.091251</td>
      <td>0.086518</td>
      <td>-0.099176</td>
      <td>-0.007368</td>
      <td>-0.035587</td>
      <td>-0.121515</td>
      <td>0.048788</td>
      <td>-0.053929</td>
      <td>0.175260</td>
    </tr>
    <tr>
      <th>NOX</th>
      <td>0.420972</td>
      <td>-0.516604</td>
      <td>0.763651</td>
      <td>0.091203</td>
      <td>1.000000</td>
      <td>-0.302188</td>
      <td>0.731470</td>
      <td>-0.769230</td>
      <td>0.611441</td>
      <td>0.668023</td>
      <td>0.188933</td>
      <td>-0.380051</td>
      <td>0.590879</td>
      <td>-0.427321</td>
    </tr>
    <tr>
      <th>RM</th>
      <td>-0.219247</td>
      <td>0.311991</td>
      <td>-0.391676</td>
      <td>0.091251</td>
      <td>-0.302188</td>
      <td>1.000000</td>
      <td>-0.240265</td>
      <td>0.205246</td>
      <td>-0.209847</td>
      <td>-0.292048</td>
      <td>-0.355501</td>
      <td>0.128069</td>
      <td>-0.613808</td>
      <td>0.695360</td>
    </tr>
    <tr>
      <th>AGE</th>
      <td>0.352734</td>
      <td>-0.569537</td>
      <td>0.644779</td>
      <td>0.086518</td>
      <td>0.731470</td>
      <td>-0.240265</td>
      <td>1.000000</td>
      <td>-0.747881</td>
      <td>0.456022</td>
      <td>0.506456</td>
      <td>0.261515</td>
      <td>-0.273534</td>
      <td>0.602339</td>
      <td>-0.376955</td>
    </tr>
    <tr>
      <th>DIS</th>
      <td>-0.379670</td>
      <td>0.664408</td>
      <td>-0.708027</td>
      <td>-0.099176</td>
      <td>-0.769230</td>
      <td>0.205246</td>
      <td>-0.747881</td>
      <td>1.000000</td>
      <td>-0.494588</td>
      <td>-0.534432</td>
      <td>-0.232471</td>
      <td>0.291512</td>
      <td>-0.496996</td>
      <td>0.249929</td>
    </tr>
    <tr>
      <th>RAD</th>
      <td>0.625505</td>
      <td>-0.311948</td>
      <td>0.595129</td>
      <td>-0.007368</td>
      <td>0.611441</td>
      <td>-0.209847</td>
      <td>0.456022</td>
      <td>-0.494588</td>
      <td>1.000000</td>
      <td>0.910228</td>
      <td>0.464741</td>
      <td>-0.444413</td>
      <td>0.488676</td>
      <td>-0.381626</td>
    </tr>
    <tr>
      <th>TAX</th>
      <td>0.582764</td>
      <td>-0.314563</td>
      <td>0.720760</td>
      <td>-0.035587</td>
      <td>0.668023</td>
      <td>-0.292048</td>
      <td>0.506456</td>
      <td>-0.534432</td>
      <td>0.910228</td>
      <td>1.000000</td>
      <td>0.460853</td>
      <td>-0.441808</td>
      <td>0.543993</td>
      <td>-0.468536</td>
    </tr>
    <tr>
      <th>PTRATIO</th>
      <td>0.289946</td>
      <td>-0.391679</td>
      <td>0.383248</td>
      <td>-0.121515</td>
      <td>0.188933</td>
      <td>-0.355501</td>
      <td>0.261515</td>
      <td>-0.232471</td>
      <td>0.464741</td>
      <td>0.460853</td>
      <td>1.000000</td>
      <td>-0.177383</td>
      <td>0.374044</td>
      <td>-0.507787</td>
    </tr>
    <tr>
      <th>B</th>
      <td>-0.385064</td>
      <td>0.175520</td>
      <td>-0.356977</td>
      <td>0.048788</td>
      <td>-0.380051</td>
      <td>0.128069</td>
      <td>-0.273534</td>
      <td>0.291512</td>
      <td>-0.444413</td>
      <td>-0.441808</td>
      <td>-0.177383</td>
      <td>1.000000</td>
      <td>-0.366087</td>
      <td>0.333461</td>
    </tr>
    <tr>
      <th>LSTAT</th>
      <td>0.455621</td>
      <td>-0.412995</td>
      <td>0.603800</td>
      <td>-0.053929</td>
      <td>0.590879</td>
      <td>-0.613808</td>
      <td>0.602339</td>
      <td>-0.496996</td>
      <td>0.488676</td>
      <td>0.543993</td>
      <td>0.374044</td>
      <td>-0.366087</td>
      <td>1.000000</td>
      <td>-0.737663</td>
    </tr>
    <tr>
      <th>PRICE</th>
      <td>-0.388305</td>
      <td>0.360445</td>
      <td>-0.483725</td>
      <td>0.175260</td>
      <td>-0.427321</td>
      <td>0.695360</td>
      <td>-0.376955</td>
      <td>0.249929</td>
      <td>-0.381626</td>
      <td>-0.468536</td>
      <td>-0.507787</td>
      <td>0.333461</td>
      <td>-0.737663</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
<p>&lt;/div&gt;</p>

<h2 id="create-a-triangular-mask-for-correlation-heatmap">Create a Triangular Mask for Correlation Heatmap</h2>

<blockquote>
  <p>To visualize the feature–feature correlations, we’ll later use a heatmap.
Since correlation matrices are symmetrical, we mask one triangle to <strong>avoid redundancy</strong>.</p>
</blockquote>

<h3 id="whats-happening-here">What’s happening here:</h3>
<ul>
  <li><code class="language-plaintext highlighter-rouge">data.corr()</code> generates the full correlation matrix.</li>
  <li><code class="language-plaintext highlighter-rouge">np.zeros_like(...)</code> creates a matrix of zeros with the same shape.</li>
  <li><code class="language-plaintext highlighter-rouge">np.triu_indices_from(mask)</code> gets the indices of the <strong>upper triangle</strong>.</li>
  <li>We set the upper triangle values in <code class="language-plaintext highlighter-rouge">mask</code> to <code class="language-plaintext highlighter-rouge">True</code> so they get hidden in the heatmap.</li>
</ul>

<blockquote>
  <p>This keeps the plot clean and focused by only showing <strong>one half of the matrix</strong>.</p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="nf">corr</span><span class="p">())</span>
<span class="n">triangle_indices</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">triu_indices_from</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
<span class="c1"># triangle_indices
</span>
<span class="n">mask</span><span class="p">[</span><span class="n">triangle_indices</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>
<span class="n">mask</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
       [0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
       [0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
       [0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
       [0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
       [0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
       [0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.],
       [0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.],
       [0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">sb</span><span class="p">.</span><span class="nf">heatmap</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="nf">corr</span><span class="p">(),</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span> <span class="sh">"</span><span class="s">RdYlBu</span><span class="sh">"</span> <span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">sb</span><span class="p">.</span><span class="nf">set_style</span><span class="p">(</span><span class="sh">"</span><span class="s">dark</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">yticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>




</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(array([ 0.5,  1.5,  2.5,  3.5,  4.5,  5.5,  6.5,  7.5,  8.5,  9.5, 10.5,
        11.5, 12.5, 13.5]),
 [Text(0, 0.5, 'CRIM'),
  Text(0, 1.5, 'ZN'),
  Text(0, 2.5, 'INDUS'),
  Text(0, 3.5, 'CHAS'),
  Text(0, 4.5, 'NOX'),
  Text(0, 5.5, 'RM'),
  Text(0, 6.5, 'AGE'),
  Text(0, 7.5, 'DIS'),
  Text(0, 8.5, 'RAD'),
  Text(0, 9.5, 'TAX'),
  Text(0, 10.5, 'PTRATIO'),
  Text(0, 11.5, 'B'),
  Text(0, 12.5, 'LSTAT'),
  Text(0, 13.5, 'PRICE')])
</code></pre></div></div>

<p><img src="/main_files/main_27_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">NOX</span><span class="p">,</span><span class="n">data</span><span class="p">.</span><span class="n">DIS</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="sh">"</span><span class="s">magenta</span><span class="sh">"</span> <span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">NOX</span><span class="sh">"</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Distance</span><span class="sh">"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">style</span><span class="p">.</span><span class="nf">use</span><span class="p">(</span><span class="sh">"</span><span class="s">classic</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlim</span><span class="p">(</span><span class="mf">0.28</span><span class="p">,</span><span class="mf">0.9</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">13</span><span class="p">)</span>
<span class="n">corr</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">NOX</span><span class="p">.</span><span class="nf">corr</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">DIS</span><span class="p">).</span><span class="nf">round</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Distance vs NOX    (Corr </span><span class="si">{</span><span class="n">corr</span><span class="si">}</span><span class="s">)</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Text(0.5, 1.0, 'Distance vs NOX    (Corr -0.769)')
</code></pre></div></div>

<p><img src="/main_files/main_28_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">sb</span><span class="p">.</span><span class="nf">jointplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">NOX</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span><span class="n">data</span><span class="p">.</span><span class="n">DIS</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="sh">"</span><span class="s">indigo</span><span class="sh">"</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span>  <span class="sh">"</span><span class="s">hist</span><span class="sh">"</span><span class="p">)</span>
<span class="n">sb</span><span class="p">.</span><span class="nf">set_style</span><span class="p">(</span><span class="sh">"</span><span class="s">darkgrid</span><span class="sh">"</span><span class="p">)</span>
<span class="n">sb</span><span class="p">.</span><span class="nf">set</span><span class="p">()</span>

</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;Figure size 1120x640 with 0 Axes&gt;
</code></pre></div></div>

<p><img src="/main_files/main_29_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">RAD</span><span class="p">,</span><span class="n">data</span><span class="p">.</span><span class="n">TAX</span> <span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="sh">"</span><span class="s">orange</span><span class="sh">"</span> <span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">TAX</span><span class="sh">"</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">RAD</span><span class="sh">"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">style</span><span class="p">.</span><span class="nf">use</span><span class="p">(</span><span class="sh">"</span><span class="s">ggplot</span><span class="sh">"</span><span class="p">)</span>

<span class="n">corr</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">TAX</span><span class="p">.</span><span class="nf">corr</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">RAD</span><span class="p">).</span><span class="nf">round</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">RAD vs TAX   (Corr </span><span class="si">{</span><span class="n">corr</span><span class="si">}</span><span class="s">)</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Text(0.5, 1.0, 'RAD vs TAX   (Corr 0.91)')
</code></pre></div></div>

<p><img src="/main_files/main_30_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">sb</span><span class="p">.</span><span class="nf">jointplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">RAD</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span><span class="n">data</span><span class="p">.</span><span class="n">TAX</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="sh">"</span><span class="s">indigo</span><span class="sh">"</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span>  <span class="sh">"</span><span class="s">reg</span><span class="sh">"</span><span class="p">)</span>
<span class="n">sb</span><span class="p">.</span><span class="nf">set_style</span><span class="p">(</span><span class="sh">"</span><span class="s">darkgrid</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;Figure size 1120x640 with 0 Axes&gt;
</code></pre></div></div>

<p><img src="/main_files/main_31_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sb</span><span class="p">.</span><span class="nf">lmplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="sh">'</span><span class="s">RAD</span><span class="sh">'</span> <span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="sh">'</span><span class="s">TAX</span><span class="sh">'</span> <span class="p">,</span><span class="n">data</span><span class="o">=</span> <span class="n">data</span> <span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/main_files/main_32_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">corr</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">PRICE</span><span class="p">.</span><span class="nf">corr</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">RM</span><span class="p">).</span><span class="nf">round</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">sb</span><span class="p">.</span><span class="nf">jointplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">RM</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span><span class="n">data</span><span class="p">.</span><span class="n">PRICE</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="sh">"</span><span class="s">indigo</span><span class="sh">"</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span>  <span class="sh">"</span><span class="s">reg</span><span class="sh">"</span><span class="p">)</span>
<span class="n">sb</span><span class="p">.</span><span class="nf">set_style</span><span class="p">(</span><span class="sh">"</span><span class="s">darkgrid</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/main_files/main_33_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sb</span><span class="p">.</span><span class="nf">pairplot</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">kind</span> <span class="o">=</span> <span class="sh">"</span><span class="s">reg</span><span class="sh">"</span><span class="p">,</span> <span class="n">plot_kws</span><span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">line_kws</span><span class="sh">'</span><span class="p">:{</span><span class="sh">'</span><span class="s">color</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">cyan</span><span class="sh">'</span><span class="p">},</span> <span class="sh">'</span><span class="s">scatter_kws</span><span class="sh">'</span><span class="p">:{</span><span class="sh">'</span><span class="s">color</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">}})</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;seaborn.axisgrid.PairGrid at 0x17ef21ed0&gt;
</code></pre></div></div>

<p><img src="/main_files/main_36_1.png" alt="png" /></p>

<h2 id="separate-features-and-target-variable">Separate Features and Target Variable</h2>

<blockquote>
  <p>We now split the dataset into:</p>
  <ul>
    <li><code class="language-plaintext highlighter-rouge">features</code>: all independent variables (used for prediction)</li>
    <li><code class="language-plaintext highlighter-rouge">prices</code>: the target variable we’re trying to predict — <code class="language-plaintext highlighter-rouge">PRICE</code></li>
  </ul>
</blockquote>

<p>We use <code class="language-plaintext highlighter-rouge">drop("PRICE", axis=1)</code> to remove the target column from the feature set.</p>

<p>This separation is important for:</p>
<ul>
  <li>Supervised learning models, which require a clear <strong>input (X)</strong> and <strong>output (y)</strong></li>
  <li>Later steps like scaling, fitting, and evaluation</li>
</ul>

<blockquote>
  <p>At this point, <code class="language-plaintext highlighter-rouge">features</code> contains all predictors and <code class="language-plaintext highlighter-rouge">prices</code> contains the house prices in $1000s.</p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">prices</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">PRICE</span>

<span class="n">features</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="sh">"</span><span class="s">PRICE</span><span class="sh">"</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>     <span class="c1">#### to remove a col off 
</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">arr</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="n">arr</span>


</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([[1, 2],
       [3, 4]])
</code></pre></div></div>

<h2 id="multivariable-linear-regression-overview">Multivariable Linear Regression Overview</h2>

<blockquote>
  <p>In multivariable linear regression, we model the target (<code class="language-plaintext highlighter-rouge">PRICE</code>) as a <strong>weighted sum of all features</strong>, plus an intercept.</p>
</blockquote>

<p>The general form of the equation is:</p>

\[\hat{\text{Price}} = \theta_0 + \theta_1 \cdot \text{RM} + \theta_2 \cdot \text{NOX} + \cdots + \theta_n \cdot N\]

<p>Where:</p>
<ul>
  <li>$\theta_0$ is the <strong>intercept</strong> (baseline price when all features are zero)</li>
  <li>$\theta_1$, $\theta_2$, …, $\theta_n$ are the <strong>coefficients</strong> (influence of each feature)</li>
  <li><code class="language-plaintext highlighter-rouge">RM</code>, <code class="language-plaintext highlighter-rouge">NOX</code>, …, <code class="language-plaintext highlighter-rouge">N</code> are the actual feature values</li>
</ul>

<blockquote>
  <p>The <strong>intercept stays constant</strong> within a model, but the $\theta$ values change depending on which features we include or exclude.</p>
</blockquote>

<p>This formula is what we estimate when we use <code class="language-plaintext highlighter-rouge">LinearRegression.fit()</code> or statsmodels’ OLS.</p>

<h2 id="split-the-data-into-training-and-test-sets">Split the Data into Training and Test Sets</h2>

<blockquote>
  <p>We split the dataset into:</p>
  <ul>
    <li><code class="language-plaintext highlighter-rouge">x_train</code>, <code class="language-plaintext highlighter-rouge">y_train</code>: used to train the model (80%)</li>
    <li><code class="language-plaintext highlighter-rouge">x_test</code>, <code class="language-plaintext highlighter-rouge">y_test</code>: used to evaluate the model’s generalization (20%)</li>
  </ul>
</blockquote>

<p>We use <code class="language-plaintext highlighter-rouge">train_test_split()</code> with:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">test_size=0.2</code> to allocate 20% of the data for testing</li>
  <li><code class="language-plaintext highlighter-rouge">random_state=10</code> to ensure reproducibility of the split</li>
</ul>

<blockquote>
  <p>Splitting the data ensures that our model isn’t evaluated on the same data it was trained on — this helps us detect overfitting.
```python
x_train,x_test,y_train,y_test = tts(features,prices,test_size=0.2,random_state=10)</p>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## Fit a Linear Regression Model

&gt; We create a `LinearRegression` object and fit it to the **training data** using `.fit(x_train, y_train)`.

This step estimates:
- the **intercept** (baseline value)
- the **coefficients** (weights for each feature)

These learned parameters define the multivariable regression equation used to predict house prices.

&gt; The second `regr_test = LR()` is likely for a later use on the test set (e.g., predicting and evaluating).

```python
regr = LR()
regr_test = LR()
regr.fit(x_train,y_train)

</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="n">regr</span><span class="p">.</span><span class="n">intercept_</span><span class="p">)</span>

<span class="n">trained_coef</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">regr</span><span class="p">.</span><span class="n">coef_</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span> <span class="n">x_train</span><span class="p">.</span><span class="n">columns</span> <span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">Coefficient</span><span class="sh">"</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>36.53305138282447
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">trained_coef</span>

</code></pre></div></div>
<p>&lt;/div&gt;</p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Coefficient</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>CRIM</th>
      <td>-0.128181</td>
    </tr>
    <tr>
      <th>ZN</th>
      <td>0.063198</td>
    </tr>
    <tr>
      <th>INDUS</th>
      <td>-0.007576</td>
    </tr>
    <tr>
      <th>CHAS</th>
      <td>1.974515</td>
    </tr>
    <tr>
      <th>NOX</th>
      <td>-16.271989</td>
    </tr>
    <tr>
      <th>RM</th>
      <td>3.108456</td>
    </tr>
    <tr>
      <th>AGE</th>
      <td>0.016292</td>
    </tr>
    <tr>
      <th>DIS</th>
      <td>-1.483014</td>
    </tr>
    <tr>
      <th>RAD</th>
      <td>0.303988</td>
    </tr>
    <tr>
      <th>TAX</th>
      <td>-0.012082</td>
    </tr>
    <tr>
      <th>PTRATIO</th>
      <td>-0.820306</td>
    </tr>
    <tr>
      <th>B</th>
      <td>0.011419</td>
    </tr>
    <tr>
      <th>LSTAT</th>
      <td>-0.581626</td>
    </tr>
  </tbody>
</table>
<p>&lt;/div&gt;</p>

<h2 id="evaluate-model-using-r-score">Evaluate Model Using R² Score</h2>

<blockquote>
  <p>We assess how well our trained model performs using the <strong>coefficient of determination (R² score)</strong>, calculated with <code class="language-plaintext highlighter-rouge">.score()</code>.</p>
</blockquote>

<ul>
  <li><code class="language-plaintext highlighter-rouge">R²</code> measures the proportion of variance in the target variable explained by the features.</li>
  <li>Ranges from 0 to 1:
    <ul>
      <li><code class="language-plaintext highlighter-rouge">1</code> means perfect prediction</li>
      <li><code class="language-plaintext highlighter-rouge">0</code> means the model does no better than the mean</li>
    </ul>
  </li>
</ul>

<p>We compute:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">r2_train</code>: model performance on the training set</li>
  <li><code class="language-plaintext highlighter-rouge">r2_test</code>: performance on unseen test data</li>
</ul>

<blockquote>
  <p>In this case:</p>
  <ul>
    <li><strong>Training R² = 0.75</strong> → decent fit to the training data</li>
    <li><strong>Testing R² = 0.67</strong> → slightly lower, indicating <strong>some generalization loss</strong> but no extreme overfitting</li>
  </ul>
</blockquote>

<p>R² gives a quick and interpretable snapshot of how well our model is capturing the underlying pattern in the data.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">r2_test</span> <span class="o">=</span> <span class="n">regr</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">)</span>
<span class="n">r2_train</span> <span class="o">=</span> <span class="n">regr</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>


<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">R2 for test data: </span><span class="si">{</span><span class="n">regr</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">)</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">R2 for trained data: </span><span class="si">{</span><span class="n">regr</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>R2 for test data: 0.6709339839115636
R2 for trained data: 0.750121534530608
</code></pre></div></div>

<h2 id="check-skewness-and-apply-log-transformation">Check Skewness and Apply Log Transformation</h2>

<blockquote>
  <p>We compute the <strong>skewness</strong> of the target variable (<code class="language-plaintext highlighter-rouge">PRICE</code>) to assess its distribution.</p>
</blockquote>

<ul>
  <li>Skewness tells us how asymmetric the data is:
    <ul>
      <li><code class="language-plaintext highlighter-rouge">0</code> = perfectly symmetric (normal)</li>
      <li>Positive skew = long right tail (common with price/income data)</li>
    </ul>
  </li>
</ul>

<p>In this case:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">prices.skew()</code> returns ≈ <strong>1.11</strong>, meaning <strong>right-skewed</strong></li>
  <li>Right-skewed data can distort regression assumptions</li>
</ul>

<blockquote>
  <p>To address this, we apply a <strong>log transformation</strong> using <code class="language-plaintext highlighter-rouge">np.log()</code>, which compresses large values and <strong>reduces skew</strong>.</p>
</blockquote>

<p>This improves linearity, stabilizes variance, and makes the model more statistically sound.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">prices</span><span class="p">.</span><span class="nf">skew</span><span class="p">()</span> 
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>np.float64(1.1080984082549072)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">prices_log</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">PRICE</span><span class="p">)</span>

<span class="n">prices_log</span><span class="p">.</span><span class="nf">skew</span><span class="p">()</span>

</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>np.float64(-0.33032129530987864)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sb</span><span class="p">.</span><span class="nf">displot</span><span class="p">(</span><span class="n">prices_log</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">maroon</span><span class="sh">"</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">"</span><span class="s">Prices with log</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Text(0.5, 1.0, 'Prices with log')
</code></pre></div></div>

<p><img src="/main_files/main_51_1.png" alt="png" /></p>

<h2 id="train-regression-model-on-log-transformed-prices">Train Regression Model on Log-Transformed Prices</h2>

<blockquote>
  <p>After reducing skewness in <code class="language-plaintext highlighter-rouge">PRICE</code> using a log transformation, we re-train the model to better meet linear regression assumptions.</p>
</blockquote>

<p>We repeat the steps:</p>
<ul>
  <li>Apply <code class="language-plaintext highlighter-rouge">train_test_split()</code> to split features and <strong>log-transformed</strong> target</li>
  <li>Initialize a new <code class="language-plaintext highlighter-rouge">LinearRegression</code> object</li>
  <li>Fit the model on training data using <code class="language-plaintext highlighter-rouge">.fit(x_train, y_train)</code></li>
</ul>

<blockquote>
  <p>Using the log of <code class="language-plaintext highlighter-rouge">PRICE</code> helps:</p>
  <ul>
    <li>Make the relationship between features and target more linear</li>
    <li>Normalize residuals</li>
    <li>Improve interpretability for percentage-based effects</li>
  </ul>
</blockquote>

<p>This model is now predicting <strong>log(price)</strong>, not raw price. We’ll exponentiate the predictions later to return to original dollar units.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">prices_log</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">PRICE</span><span class="p">)</span>

<span class="n">x_train</span><span class="p">,</span><span class="n">x_test</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">y_test</span><span class="o">=</span> <span class="nf">tts</span><span class="p">(</span><span class="n">features</span> <span class="p">,</span> <span class="n">prices_log</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span>

<span class="n">log_reg</span> <span class="o">=</span> <span class="nc">LR</span><span class="p">()</span>

<span class="n">log_reg</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>

</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">Coeff</span><span class="sh">"</span><span class="p">],</span> <span class="n">data</span><span class="o">=</span><span class="n">log_reg</span><span class="p">.</span><span class="n">coef_</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">features</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>
</code></pre></div></div>
<p>&lt;/div&gt;</p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Coeff</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>CRIM</th>
      <td>-0.010672</td>
    </tr>
    <tr>
      <th>ZN</th>
      <td>0.001579</td>
    </tr>
    <tr>
      <th>INDUS</th>
      <td>0.002030</td>
    </tr>
    <tr>
      <th>CHAS</th>
      <td>0.080331</td>
    </tr>
    <tr>
      <th>NOX</th>
      <td>-0.704068</td>
    </tr>
    <tr>
      <th>RM</th>
      <td>0.073404</td>
    </tr>
    <tr>
      <th>AGE</th>
      <td>0.000763</td>
    </tr>
    <tr>
      <th>DIS</th>
      <td>-0.047633</td>
    </tr>
    <tr>
      <th>RAD</th>
      <td>0.014565</td>
    </tr>
    <tr>
      <th>TAX</th>
      <td>-0.000645</td>
    </tr>
    <tr>
      <th>PTRATIO</th>
      <td>-0.034795</td>
    </tr>
    <tr>
      <th>B</th>
      <td>0.000516</td>
    </tr>
    <tr>
      <th>LSTAT</th>
      <td>-0.031390</td>
    </tr>
  </tbody>
</table>
<p>&lt;/div&gt;</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Intercept : </span><span class="si">{</span><span class="n">log_reg</span><span class="p">.</span><span class="n">intercept_</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Intercept : 4.059943871775207
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">R2 value of Trained set : </span><span class="si">{</span><span class="n">log_reg</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">R2 value of Test set : </span><span class="si">{</span><span class="n">log_reg</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">)</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>R2 value of Trained set : 0.7930234826697584
R2 value of Test set : 0.7446922306260739
</code></pre></div></div>

<h3 id="p-values-and-evaluating-coeffs">P values and evaluating Coeffs</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x_incl_const</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="nf">add_constant</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="nc">OLS</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span><span class="n">x_incl_const</span><span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">({</span><span class="sh">"</span><span class="s">Coef</span><span class="sh">"</span><span class="p">:</span><span class="n">results</span><span class="p">.</span><span class="n">params</span><span class="p">,</span> <span class="sh">"</span><span class="s">Pvalues</span><span class="sh">"</span><span class="p">:</span><span class="nf">round</span><span class="p">(</span><span class="n">results</span><span class="p">.</span><span class="n">pvalues</span><span class="p">,</span><span class="mi">3</span><span class="p">)})</span>
</code></pre></div></div>
<p>&lt;/div&gt;</p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Coef</th>
      <th>Pvalues</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>const</th>
      <td>4.059944</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>CRIM</th>
      <td>-0.010672</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>ZN</th>
      <td>0.001579</td>
      <td>0.009</td>
    </tr>
    <tr>
      <th>INDUS</th>
      <td>0.002030</td>
      <td>0.445</td>
    </tr>
    <tr>
      <th>CHAS</th>
      <td>0.080331</td>
      <td>0.038</td>
    </tr>
    <tr>
      <th>NOX</th>
      <td>-0.704068</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>RM</th>
      <td>0.073404</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>AGE</th>
      <td>0.000763</td>
      <td>0.209</td>
    </tr>
    <tr>
      <th>DIS</th>
      <td>-0.047633</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>RAD</th>
      <td>0.014565</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>TAX</th>
      <td>-0.000645</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>PTRATIO</th>
      <td>-0.034795</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>B</th>
      <td>0.000516</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>LSTAT</th>
      <td>-0.031390</td>
      <td>0.000</td>
    </tr>
  </tbody>
</table>
<p>&lt;/div&gt;</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">results</span><span class="p">.</span><span class="n">rsquared</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>np.float64(0.7930234826697584)
</code></pre></div></div>

<h2 id="testing-for-multicollinearity-with-vif">Testing for Multicollinearity with VIF</h2>

<blockquote>
  <p>Multicollinearity occurs when features are highly correlated with each other, which can make the regression model unstable or misleading.</p>
</blockquote>

<p>We test for this using <strong>VIF (Variance Inflation Factor)</strong>:</p>
<ul>
  <li>VIF measures how much a feature is “inflated” due to correlation with other features.</li>
  <li>Formula:<br />
\(\text{VIF}_i = \frac{1}{1 - R^2_i}\)<br />
where ( R^2_i ) is the R² value from regressing the <em>i-th</em> feature on all others.</li>
</ul>

<blockquote>
  <p><strong>Interpretation:</strong></p>
  <ul>
    <li>VIF = 1 → no multicollinearity</li>
    <li>VIF = 1–5 → okay</li>
    <li>VIF = 5–10 → moderate, keep an eye</li>
    <li>VIF &gt; 10 → <strong>serious multicollinearity</strong>, consider dropping that feature</li>
  </ul>
</blockquote>

<p>By calculating VIF for all features, we can identify which ones are redundant and safely remove them to improve model reliability and interpretability.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># VIF = vif(exog = x_incl_const.values ,exog_idx=13 )
# VIF
</span><span class="n">vif_list</span>  <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="nf">len</span><span class="p">(</span><span class="n">x_incl_const</span><span class="p">.</span><span class="n">columns</span><span class="p">)):</span>
    <span class="n">VIF</span> <span class="o">=</span>  <span class="nf">vif</span><span class="p">(</span><span class="n">exog</span><span class="o">=</span> <span class="n">x_incl_const</span><span class="p">.</span><span class="n">values</span><span class="p">,</span><span class="n">exog_idx</span><span class="o">=</span> <span class="n">i</span> <span class="p">)</span>
    <span class="n">vif_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">VIF</span><span class="p">)</span>

<span class="n">vif_list</span>    
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[np.float64(1.714525044393249),
 np.float64(2.3328224265597597),
 np.float64(3.943448822674638),
 np.float64(1.0788133385000576),
 np.float64(4.410320817897634),
 np.float64(1.8404053075678568),
 np.float64(3.3267660823099394),
 np.float64(4.222923410477865),
 np.float64(7.314299817005058),
 np.float64(8.508856493040817),
 np.float64(1.8399116326514058),
 np.float64(1.338671325536472),
 np.float64(2.812544292793035)]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">type</span><span class="p">(</span><span class="n">x_incl_const</span><span class="p">)</span>
<span class="nf">type</span><span class="p">(</span><span class="n">x_incl_const</span><span class="p">.</span><span class="n">values</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>numpy.ndarray
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">len</span><span class="p">(</span><span class="n">x_incl_const</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>14
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">vif_list</span>  <span class="o">=</span> <span class="p">[</span> <span class="nf">vif</span><span class="p">(</span><span class="n">exog</span><span class="o">=</span> <span class="n">x_incl_const</span><span class="p">.</span><span class="n">values</span><span class="p">,</span><span class="n">exog_idx</span><span class="o">=</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="nf">len</span><span class="p">(</span><span class="n">x_incl_const</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span> <span class="p">)</span> <span class="p">]</span>

<span class="n">vif_list</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[np.float64(1.714525044393249),
 np.float64(2.3328224265597597),
 np.float64(3.943448822674638),
 np.float64(1.0788133385000576),
 np.float64(4.410320817897634),
 np.float64(1.8404053075678568),
 np.float64(3.3267660823099394),
 np.float64(4.222923410477865),
 np.float64(7.314299817005058),
 np.float64(8.508856493040817),
 np.float64(1.8399116326514058),
 np.float64(1.338671325536472),
 np.float64(2.812544292793035)]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">({</span><span class="sh">"</span><span class="s">coef_name</span><span class="sh">"</span><span class="p">:</span> <span class="n">features</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span><span class="sh">"</span><span class="s">VIF</span><span class="sh">"</span><span class="p">:</span><span class="n">vif_list</span><span class="p">}</span> <span class="p">)</span>
</code></pre></div></div>
<p>&lt;/div&gt;</p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>coef_name</th>
      <th>VIF</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>CRIM</td>
      <td>1.714525</td>
    </tr>
    <tr>
      <th>1</th>
      <td>ZN</td>
      <td>2.332822</td>
    </tr>
    <tr>
      <th>2</th>
      <td>INDUS</td>
      <td>3.943449</td>
    </tr>
    <tr>
      <th>3</th>
      <td>CHAS</td>
      <td>1.078813</td>
    </tr>
    <tr>
      <th>4</th>
      <td>NOX</td>
      <td>4.410321</td>
    </tr>
    <tr>
      <th>5</th>
      <td>RM</td>
      <td>1.840405</td>
    </tr>
    <tr>
      <th>6</th>
      <td>AGE</td>
      <td>3.326766</td>
    </tr>
    <tr>
      <th>7</th>
      <td>DIS</td>
      <td>4.222923</td>
    </tr>
    <tr>
      <th>8</th>
      <td>RAD</td>
      <td>7.314300</td>
    </tr>
    <tr>
      <th>9</th>
      <td>TAX</td>
      <td>8.508856</td>
    </tr>
    <tr>
      <th>10</th>
      <td>PTRATIO</td>
      <td>1.839912</td>
    </tr>
    <tr>
      <th>11</th>
      <td>B</td>
      <td>1.338671</td>
    </tr>
    <tr>
      <th>12</th>
      <td>LSTAT</td>
      <td>2.812544</td>
    </tr>
  </tbody>
</table>
<p>&lt;/div&gt;</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

<h2 id="model-simplification-using-bayesian-information-criterion-bic">Model Simplification Using Bayesian Information Criterion (BIC)</h2>

<blockquote>
  <p>Once we have several candidate models, we use <strong>Bayesian Information Criterion (BIC)</strong> to compare them.</p>
</blockquote>

<p>BIC helps us balance:</p>
<ul>
  <li><strong>Model fit</strong> (how well the model explains the data)</li>
  <li><strong>Model complexity</strong> (how many features are used)</li>
</ul>

<blockquote>
  <p>The key idea:</p>
  <ul>
    <li><strong>Lower BIC = better model</strong></li>
    <li>BIC penalizes models with more features, discouraging overfitting</li>
  </ul>
</blockquote>

<p>We may try simplified versions of the model by:</p>
<ul>
  <li>Removing weak or redundant features (like <code class="language-plaintext highlighter-rouge">INDUS</code> and <code class="language-plaintext highlighter-rouge">AGE</code>)</li>
  <li>Re-fitting the model</li>
  <li>Selecting the version with the <strong>lowest BIC</strong></li>
</ul>

<blockquote>
  <p>This ensures the model generalizes better while staying interpretable.</p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">results</span><span class="p">.</span><span class="nf">summary</span><span class="p">()</span>
</code></pre></div></div>

<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>          <td>PRICE</td>      <th>  R-squared:         </th> <td>   0.793</td> 
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.786</td> 
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   114.9</td> 
</tr>
<tr>
  <th>Date:</th>             <td>Mon, 26 May 2025</td> <th>  Prob (F-statistic):</th> <td>1.70e-124</td>
</tr>
<tr>
  <th>Time:</th>                 <td>05:17:07</td>     <th>  Log-Likelihood:    </th> <td>  111.88</td> 
</tr>
<tr>
  <th>No. Observations:</th>      <td>   404</td>      <th>  AIC:               </th> <td>  -195.8</td> 
</tr>
<tr>
  <th>Df Residuals:</th>          <td>   390</td>      <th>  BIC:               </th> <td>  -139.7</td> 
</tr>
<tr>
  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>     <td> </td>    
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    
</tr>
</table>
<table class="simpletable">
<tr>
     <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P&gt;|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>const</th>   <td>    4.0599</td> <td>    0.227</td> <td>   17.880</td> <td> 0.000</td> <td>    3.614</td> <td>    4.506</td>
</tr>
<tr>
  <th>CRIM</th>    <td>   -0.0107</td> <td>    0.001</td> <td>   -7.971</td> <td> 0.000</td> <td>   -0.013</td> <td>   -0.008</td>
</tr>
<tr>
  <th>ZN</th>      <td>    0.0016</td> <td>    0.001</td> <td>    2.641</td> <td> 0.009</td> <td>    0.000</td> <td>    0.003</td>
</tr>
<tr>
  <th>INDUS</th>   <td>    0.0020</td> <td>    0.003</td> <td>    0.765</td> <td> 0.445</td> <td>   -0.003</td> <td>    0.007</td>
</tr>
<tr>
  <th>CHAS</th>    <td>    0.0803</td> <td>    0.039</td> <td>    2.079</td> <td> 0.038</td> <td>    0.004</td> <td>    0.156</td>
</tr>
<tr>
  <th>NOX</th>     <td>   -0.7041</td> <td>    0.166</td> <td>   -4.245</td> <td> 0.000</td> <td>   -1.030</td> <td>   -0.378</td>
</tr>
<tr>
  <th>RM</th>      <td>    0.0734</td> <td>    0.019</td> <td>    3.910</td> <td> 0.000</td> <td>    0.036</td> <td>    0.110</td>
</tr>
<tr>
  <th>AGE</th>     <td>    0.0008</td> <td>    0.001</td> <td>    1.258</td> <td> 0.209</td> <td>   -0.000</td> <td>    0.002</td>
</tr>
<tr>
  <th>DIS</th>     <td>   -0.0476</td> <td>    0.009</td> <td>   -5.313</td> <td> 0.000</td> <td>   -0.065</td> <td>   -0.030</td>
</tr>
<tr>
  <th>RAD</th>     <td>    0.0146</td> <td>    0.003</td> <td>    5.170</td> <td> 0.000</td> <td>    0.009</td> <td>    0.020</td>
</tr>
<tr>
  <th>TAX</th>     <td>   -0.0006</td> <td>    0.000</td> <td>   -4.095</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.000</td>
</tr>
<tr>
  <th>PTRATIO</th> <td>   -0.0348</td> <td>    0.006</td> <td>   -5.908</td> <td> 0.000</td> <td>   -0.046</td> <td>   -0.023</td>
</tr>
<tr>
  <th>B</th>       <td>    0.0005</td> <td>    0.000</td> <td>    4.578</td> <td> 0.000</td> <td>    0.000</td> <td>    0.001</td>
</tr>
<tr>
  <th>LSTAT</th>   <td>   -0.0314</td> <td>    0.002</td> <td>  -14.213</td> <td> 0.000</td> <td>   -0.036</td> <td>   -0.027</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>28.711</td> <th>  Durbin-Watson:     </th> <td>   2.059</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 105.952</td>
</tr>
<tr>
  <th>Skew:</th>          <td> 0.093</td> <th>  Prob(JB):          </th> <td>9.84e-24</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 5.502</td> <th>  Cond. No.          </th> <td>1.54e+04</td>
</tr>
</table>
<p><br /><br />Notes:<br />[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br />[2] The condition number is large, 1.54e+04. This might indicate that there are<br />strong multicollinearity or other numerical problems.</p>

<h2 id="simplifying-the-model-with-bic-and-r">Simplifying the Model with BIC and R²</h2>

<blockquote>
  <p>To improve model generalization and interpretability, we simplify the regression model by <strong>removing less important features</strong> and evaluating each version using:</p>
  <ul>
    <li><strong>BIC (Bayesian Information Criterion)</strong> — lower is better</li>
    <li><strong>R² (explained variance)</strong> — higher is better</li>
  </ul>
</blockquote>

<h3 id="model-2-removed-indus">Model 2: Removed <code class="language-plaintext highlighter-rouge">INDUS</code></h3>
<ul>
  <li>Dropping <code class="language-plaintext highlighter-rouge">INDUS</code> led to:
    <ul>
      <li><strong>BIC = -145.145</strong></li>
      <li><strong>R² = 0.793</strong></li>
    </ul>
  </li>
  <li>This indicates a good balance between simplicity and predictive power.</li>
</ul>

<h3 id="model-3-removed-indus-and-age">Model 3: Removed <code class="language-plaintext highlighter-rouge">INDUS</code> and <code class="language-plaintext highlighter-rouge">AGE</code></h3>
<ul>
  <li>Further removed <code class="language-plaintext highlighter-rouge">AGE</code> to reduce complexity</li>
  <li>Reran the regression and compared results</li>
</ul>

<blockquote>
  <p>By iteratively dropping features and comparing metrics, we choose the version with the <strong>lowest BIC</strong> that still maintains strong explanatory performance.</p>
</blockquote>

<p>This step helps us lock in a <strong>minimal yet effective feature set</strong> before final residual checks and predictions.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">##Model 1
</span>
<span class="n">x_incl_const</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="nf">add_constant</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>

<span class="n">model_1</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="nc">OLS</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span><span class="n">x_incl_const</span><span class="p">)</span>

<span class="n">result_1</span> <span class="o">=</span> <span class="n">model_1</span><span class="p">.</span><span class="nf">fit</span><span class="p">()</span>

<span class="n">model_1</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">({</span><span class="sh">"</span><span class="s">Coef</span><span class="sh">"</span><span class="p">:</span><span class="n">result_1</span><span class="p">.</span><span class="n">params</span><span class="p">,</span> <span class="sh">"</span><span class="s">Pvalues</span><span class="sh">"</span><span class="p">:</span><span class="nf">round</span><span class="p">(</span><span class="n">result_1</span><span class="p">.</span><span class="n">pvalues</span><span class="p">,</span><span class="mi">3</span><span class="p">)})</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">BIC: </span><span class="si">{</span><span class="nf">round</span><span class="p">(</span><span class="n">result_1</span><span class="p">.</span><span class="n">bic</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span> 
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Rsquared : </span><span class="si">{</span><span class="nf">round</span><span class="p">(</span><span class="n">result_1</span><span class="p">.</span><span class="n">rsquared</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span> 
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>BIC: -139.75
Rsquared : 0.793
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Model 2 without INDUS
</span>
<span class="n">x_incl_const</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="nf">add_constant</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>
<span class="n">x_incl_const</span> <span class="o">=</span><span class="n">x_incl_const</span><span class="p">.</span><span class="nf">drop</span><span class="p">([</span><span class="sh">"</span><span class="s">INDUS</span><span class="sh">"</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">model_2</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="nc">OLS</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span><span class="n">x_incl_const</span><span class="p">)</span>

<span class="n">result_2</span> <span class="o">=</span> <span class="n">model_2</span><span class="p">.</span><span class="nf">fit</span><span class="p">()</span>

<span class="n">model_2</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">({</span><span class="sh">"</span><span class="s">Coef</span><span class="sh">"</span><span class="p">:</span><span class="n">result_2</span><span class="p">.</span><span class="n">params</span><span class="p">,</span> <span class="sh">"</span><span class="s">Pvalues</span><span class="sh">"</span><span class="p">:</span><span class="nf">round</span><span class="p">(</span><span class="n">result_2</span><span class="p">.</span><span class="n">pvalues</span><span class="p">,</span><span class="mi">3</span><span class="p">)})</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">BIC: </span><span class="si">{</span><span class="nf">round</span><span class="p">(</span><span class="n">result_2</span><span class="p">.</span><span class="n">bic</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span> 
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Rsquared : </span><span class="si">{</span><span class="nf">round</span><span class="p">(</span><span class="n">result_2</span><span class="p">.</span><span class="n">rsquared</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span> 
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>BIC: -145.145
Rsquared : 0.793
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Model 3 without INDUS &amp; AGE
</span>
<span class="n">x_incl_const</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="nf">add_constant</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>
<span class="n">x_incl_const</span> <span class="o">=</span><span class="n">x_incl_const</span><span class="p">.</span><span class="nf">drop</span><span class="p">([</span><span class="sh">"</span><span class="s">INDUS</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">AGE</span><span class="sh">"</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">model_3</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="nc">OLS</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span><span class="n">x_incl_const</span><span class="p">)</span>

<span class="n">result_3</span> <span class="o">=</span> <span class="n">model_3</span><span class="p">.</span><span class="nf">fit</span><span class="p">()</span>

<span class="n">model_3</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">({</span><span class="sh">"</span><span class="s">Coef</span><span class="sh">"</span><span class="p">:</span><span class="n">result_3</span><span class="p">.</span><span class="n">params</span><span class="p">,</span> <span class="sh">"</span><span class="s">Pvalues</span><span class="sh">"</span><span class="p">:</span><span class="nf">round</span><span class="p">(</span><span class="n">result_3</span><span class="p">.</span><span class="n">pvalues</span><span class="p">,</span><span class="mi">3</span><span class="p">)})</span>


<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">BIC: </span><span class="si">{</span><span class="nf">round</span><span class="p">(</span><span class="n">result_3</span><span class="p">.</span><span class="n">bic</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span> 
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Rsquared : </span><span class="si">{</span><span class="nf">round</span><span class="p">(</span><span class="n">result_3</span><span class="p">.</span><span class="n">rsquared</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span> 
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>BIC: -149.499
Rsquared : 0.792
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">models_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">model_1</span><span class="p">,</span><span class="n">model_2</span><span class="p">,</span><span class="n">model_3</span><span class="p">]</span>

<span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">(</span><span class="n">models_list</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>
<p>&lt;/div&gt;</p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Coef</th>
      <th>Pvalues</th>
      <th>Coef</th>
      <th>Pvalues</th>
      <th>Coef</th>
      <th>Pvalues</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>const</th>
      <td>4.059944</td>
      <td>0.000</td>
      <td>4.056231</td>
      <td>0.000</td>
      <td>4.035922</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>CRIM</th>
      <td>-0.010672</td>
      <td>0.000</td>
      <td>-0.010721</td>
      <td>0.000</td>
      <td>-0.010702</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>ZN</th>
      <td>0.001579</td>
      <td>0.009</td>
      <td>0.001551</td>
      <td>0.010</td>
      <td>0.001461</td>
      <td>0.014</td>
    </tr>
    <tr>
      <th>INDUS</th>
      <td>0.002030</td>
      <td>0.445</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>CHAS</th>
      <td>0.080331</td>
      <td>0.038</td>
      <td>0.082795</td>
      <td>0.032</td>
      <td>0.086449</td>
      <td>0.025</td>
    </tr>
    <tr>
      <th>NOX</th>
      <td>-0.704068</td>
      <td>0.000</td>
      <td>-0.673365</td>
      <td>0.000</td>
      <td>-0.616448</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>RM</th>
      <td>0.073404</td>
      <td>0.000</td>
      <td>0.071739</td>
      <td>0.000</td>
      <td>0.076133</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>AGE</th>
      <td>0.000763</td>
      <td>0.209</td>
      <td>0.000766</td>
      <td>0.207</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>DIS</th>
      <td>-0.047633</td>
      <td>0.000</td>
      <td>-0.049394</td>
      <td>0.000</td>
      <td>-0.052692</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>RAD</th>
      <td>0.014565</td>
      <td>0.000</td>
      <td>0.014014</td>
      <td>0.000</td>
      <td>0.013743</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>TAX</th>
      <td>-0.000645</td>
      <td>0.000</td>
      <td>-0.000596</td>
      <td>0.000</td>
      <td>-0.000590</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>PTRATIO</th>
      <td>-0.034795</td>
      <td>0.000</td>
      <td>-0.034126</td>
      <td>0.000</td>
      <td>-0.033481</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>B</th>
      <td>0.000516</td>
      <td>0.000</td>
      <td>0.000511</td>
      <td>0.000</td>
      <td>0.000518</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>LSTAT</th>
      <td>-0.031390</td>
      <td>0.000</td>
      <td>-0.031262</td>
      <td>0.000</td>
      <td>-0.030271</td>
      <td>0.000</td>
    </tr>
  </tbody>
</table>
<p>&lt;/div&gt;</p>

<h2 id="residuals-and-plots">Residuals and plots</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">### Latest model
</span>
<span class="n">prices_log</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">PRICE</span><span class="p">)</span>
<span class="c1"># features = features.drop(["AGE","INDUS"], axis = 1)
</span>
<span class="n">x_train</span><span class="p">,</span><span class="n">x_test</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">y_test</span><span class="o">=</span> <span class="nf">tts</span><span class="p">(</span><span class="n">features</span> <span class="p">,</span> <span class="n">prices_log</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span>

<span class="n">log_reg</span> <span class="o">=</span> <span class="nc">LR</span><span class="p">()</span>

<span class="n">log_reg</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>

<span class="n">x_incl_const</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="nf">add_constant</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>
<span class="c1"># x_incl_const =x_incl_const.drop(["INDUS","AGE"],axis=1)
</span>
<span class="n">model_x</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="nc">OLS</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span><span class="n">x_incl_const</span><span class="p">)</span>

<span class="n">result_x</span> <span class="o">=</span> <span class="n">model_x</span><span class="p">.</span><span class="nf">fit</span><span class="p">()</span>

<span class="n">model_x</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">({</span><span class="sh">"</span><span class="s">Coef</span><span class="sh">"</span><span class="p">:</span><span class="n">result_x</span><span class="p">.</span><span class="n">params</span><span class="p">,</span> <span class="sh">"</span><span class="s">Pvalues</span><span class="sh">"</span><span class="p">:</span><span class="nf">round</span><span class="p">(</span><span class="n">result_x</span><span class="p">.</span><span class="n">pvalues</span><span class="p">,</span><span class="mi">3</span><span class="p">)})</span>


<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">BIC: </span><span class="si">{</span><span class="nf">round</span><span class="p">(</span><span class="n">result_x</span><span class="p">.</span><span class="n">bic</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span> 
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Rsquared : </span><span class="si">{</span><span class="nf">round</span><span class="p">(</span><span class="n">result_x</span><span class="p">.</span><span class="n">rsquared</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span> 
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>BIC: -149.499
Rsquared : 0.792
</code></pre></div></div>

<h2 id="residual-analysis-and-model-diagnostics">Residual Analysis and Model Diagnostics</h2>

<blockquote>
  <p>After finalizing our simplified regression model, we perform residual analysis to verify key assumptions and assess model quality.
residuals = y_train - predicted_y</p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># residuals = y_train - result_x.fittedvalues   ##fitted values r predicted y
</span>
<span class="n">residuals</span> <span class="o">=</span> <span class="n">result_x</span><span class="p">.</span><span class="n">resid</span>
<span class="n">residuals</span><span class="p">.</span><span class="nf">describe</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>count    4.040000e+02
mean    -3.004747e-15
std      1.841779e-01
min     -7.330963e-01
25%     -9.881733e-02
50%     -1.499545e-02
75%      9.870289e-02
max      7.907087e-01
dtype: float64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">residuals</span> <span class="o">=</span> <span class="n">result_x</span><span class="p">.</span><span class="n">resid</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>50    -0.056143
367    0.498215
34    -0.033868
78     0.043520
172    0.033242
         ...   
320   -0.041251
15    -0.033156
484    0.074891
125    0.008542
265   -0.214594
Length: 404, dtype: float64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">corr</span> <span class="o">=</span> <span class="p">(</span><span class="nf">round</span><span class="p">(</span><span class="n">y_train</span><span class="p">.</span><span class="nf">corr</span><span class="p">(</span><span class="n">result_x</span><span class="p">.</span><span class="n">fittedvalues</span><span class="p">)</span> <span class="p">,</span><span class="mi">3</span><span class="p">))</span> <span class="c1">## correlation btw original y values vs predicted y
</span><span class="n">corr</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>np.float64(0.89)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">result_x</span><span class="p">.</span><span class="n">fittedvalues</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="sh">"</span><span class="s">turquoise</span><span class="sh">"</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="sh">"</span><span class="s">black</span><span class="sh">"</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="sh">"</span><span class="s">grey</span><span class="sh">"</span> <span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.4</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Original Values</span><span class="sh">"</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Predicted Values</span><span class="sh">"</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Values in log   (Corr:</span><span class="si">{</span><span class="n">corr</span><span class="si">}</span><span class="s">)</span><span class="sh">"</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlim</span><span class="p">(</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">4.1</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(1.5, 4.1)
</code></pre></div></div>

<p><img src="/main_files/main_84_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">e</span><span class="o">**</span><span class="n">y_train</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">e</span><span class="o">**</span><span class="n">result_x</span><span class="p">.</span><span class="n">fittedvalues</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="sh">"</span><span class="s">navy</span><span class="sh">"</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="sh">"</span><span class="s">black</span><span class="sh">"</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">e</span><span class="o">**</span><span class="n">y_train</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">e</span><span class="o">**</span><span class="n">y_train</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="sh">"</span><span class="s">grey</span><span class="sh">"</span> <span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.4</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Original Values</span><span class="sh">"</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Predicted Values</span><span class="sh">"</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Residual Test (Corr:</span><span class="si">{</span><span class="n">corr</span><span class="si">}</span><span class="s">)</span><span class="sh">"</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlim</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">52</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(2.0, 52.0)
</code></pre></div></div>

<p><img src="/main_files/main_85_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">result_x</span><span class="p">.</span><span class="n">fittedvalues</span><span class="p">,</span><span class="n">result_x</span><span class="p">.</span><span class="n">resid</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="sh">"</span><span class="s">lime</span><span class="sh">"</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="sh">"</span><span class="s">black</span><span class="sh">"</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">)</span>
<span class="c1"># plt.plot(y_train, y_train, color = "grey" , alpha = 0.6)
</span><span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Residuals</span><span class="sh">"</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Predicted Values</span><span class="sh">"</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Values in log</span><span class="sh">"</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/main_files/main_86_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">e</span><span class="o">**</span><span class="n">result_x</span><span class="p">.</span><span class="n">fittedvalues</span><span class="p">,</span><span class="n">np</span><span class="p">.</span><span class="n">e</span><span class="o">**</span><span class="n">result_x</span><span class="p">.</span><span class="n">resid</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="sh">"</span><span class="s">red</span><span class="sh">"</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="sh">"</span><span class="s">black</span><span class="sh">"</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Residuals</span><span class="sh">"</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Predicted Values</span><span class="sh">"</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Values in 000s</span><span class="sh">"</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/main_files/main_87_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">residual_mean</span> <span class="o">=</span> <span class="nf">round</span><span class="p">(</span><span class="n">result_x</span><span class="p">.</span><span class="n">resid</span><span class="p">.</span><span class="nf">mean</span><span class="p">(),</span><span class="mi">2</span><span class="p">)</span>
<span class="n">residual_skew</span> <span class="o">=</span> <span class="nf">round</span><span class="p">(</span><span class="n">result_x</span><span class="p">.</span><span class="n">resid</span><span class="p">.</span><span class="nf">skew</span><span class="p">(),</span><span class="mi">2</span><span class="p">)</span>

</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>np.float64(-0.0)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">sb</span><span class="p">.</span><span class="nf">displot</span><span class="p">(</span><span class="n">result_x</span><span class="p">.</span><span class="n">resid</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="bp">True</span> <span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="sh">"</span><span class="s">#FC427B</span><span class="sh">"</span> <span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="sh">"</span><span class="s">black</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Values in log (Mean: </span><span class="si">{</span><span class="n">residual_mean</span><span class="si">}</span><span class="s">, Skew: </span><span class="si">{</span><span class="n">residual_skew</span><span class="si">}</span><span class="s">)</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Residual</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Text(0.5, 6.444444444444427, 'Residual')




&lt;Figure size 1120x640 with 0 Axes&gt;
</code></pre></div></div>

<p><img src="/main_files/main_89_2.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">result_x</span><span class="p">.</span><span class="n">mse_resid</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>np.float64(0.03487337082354599)
</code></pre></div></div>

<h2 id="estimating-a-prediction-range-with-rmse">Estimating a Prediction Range with RMSE</h2>

<blockquote>
  <p>After calculating the <strong>Mean Squared Error (MSE)</strong>, we take its square root to get <strong>Root Mean Squared Error (RMSE)</strong>, which serves as a stand-in for <strong>standard deviation</strong> of our model’s error.</p>
</blockquote>

<ul>
  <li>RMSE ≈ Standard Deviation of residuals</li>
  <li>For a normally distributed variable:
    <ul>
      <li>~68% of values lie within ±1 RMSE</li>
      <li>~95% lie within ±2 RMSE</li>
    </ul>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">### IF WE SQRT THE MSE , RMSE = STANDARD DEVIATION AND 95% VALUES FALL BTW +-2 SD , 67% +- 1SD
</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">1SE in log prices</span><span class="sh">"</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">result_x</span><span class="p">.</span><span class="n">mse_resid</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">2SE in log prices</span><span class="sh">"</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">result_x</span><span class="p">.</span><span class="n">mse_resid</span><span class="p">))</span>

<span class="n">upper_bound</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">results</span><span class="p">.</span><span class="n">mse_resid</span><span class="p">)</span>
<span class="n">lower_bound</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span><span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">results</span><span class="p">.</span><span class="n">mse_resid</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">The upper bound in log prices for 95% prediction interval is </span><span class="sh">"</span><span class="p">,</span> <span class="n">upper_bound</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">The upper bound in normal prices  </span><span class="sh">"</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">e</span><span class="o">**</span> <span class="n">upper_bound</span> <span class="o">*</span><span class="mi">1000</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">The lower bound in log prices for 95% prediction interval is </span><span class="sh">"</span><span class="p">,</span> <span class="n">lower_bound</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">The lower bound in normal prices  </span><span class="sh">"</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">e</span><span class="o">**</span> <span class="n">lower_bound</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1SE in log prices 0.18674413196549441
2SE in log prices 0.37348826393098883
The upper bound in log prices for 95% prediction interval is  3.774599233809198
The upper bound in normal prices   43580.03940909473
The lower bound in log prices for 95% prediction interval is  3.027795529515113
The lower bound in normal prices   20651.656405160997
</code></pre></div></div>

<hr />

<p>That wraps up the main parts of this project for now. I’ve focused on a few steps that I found especially useful while exploring regression — from preprocessing and multicollinearity checks to evaluating model fit with BIC and inspecting residuals.</p>

<p>In the next part, we’ll continue by actually using the model to make predictions — including calculating upper and lower bounds to estimate a range of possible prices.</p>

<p>Thanks for reading, and see you in the next post!</p>


  </div><a class="u-url" href="/2024/07/01/boston-house-regression_preprocessing.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Bioinformatics for Beginners</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Tushar Singh</li><li><a class="u-email" href="mailto:tushar14032001@gmail.com">tushar14032001@gmail.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>A blog by Tushar to simplify bioinformatics and machine learning</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
